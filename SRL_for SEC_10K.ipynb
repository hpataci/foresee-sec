{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SRL_Sec_parsing_seperate_files.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FVEjMjoFOco9",
        "colab": {}
      },
      "source": [
        "\n",
        "import nltk.data\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "import types\n",
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "!pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
        "#from allennlp.predictors.predictor import Predictor\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dJRQFHyKOcpB",
        "colab": {}
      },
      "source": [
        "#txt='../sec_cleaning/txt/' #path of txt files from SEC-cleaned\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nAlPoTIEOcpE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "0a0a4039-0f12-4352-b2f7-b6c9ec94ff5c"
      },
      "source": [
        "import glob,os\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "print(os.getcwd())\n",
        "\n",
        "os.chdir(\"/content/gdrive/My Drive/Colab Notebooks/sec_cleaning/txt\")\n",
        "\n",
        "\n",
        "print(os.getcwd())\n",
        "\n",
        "if( not os.path.isdir(os.getcwd()+\"/output/\")):\n",
        "  os.mkdir(os.getcwd()+\"/output/\")\n",
        "  print(os.getcwd()+\"/output/\")\n",
        "  print(\"directory is created\")\n",
        "else:\n",
        "  print(os.getcwd()+\"/output/\")\n",
        "  print(\"directory already exists\")\n",
        "  \n",
        "import MyFun,variables \n",
        "\n",
        "\n",
        "#MyFun.yourName(\"Aduket\")\n",
        "\n",
        "#os.chdir(\"../sec_cleaning/txt\")\n",
        "#print(os.getcwd())\n",
        "#breakpoint()\n",
        "rid = 0\n",
        "sentences = {}\n",
        "filenames=[]\n",
        "\n",
        "prefixed_files = [filename for filename in glob.glob(\"*.txt\") if filename.startswith(\"AAL_\")]\n",
        "\n",
        "#read file path\n",
        "\n",
        "# for all files replace the below line with the other loop below\n",
        "\n",
        "#for text_path in glob.glob(\"*.txt\"):\n",
        "for text_path in prefixed_files:\n",
        "    #print(text_path)\n",
        "    #read all txt file \n",
        "    text = Path(text_path).read_text()\n",
        "    filenames.append(os.path.basename(text_path))\n",
        "    #breakpoint()\n",
        "    #print(text)\n",
        "    #breakpoint()\n",
        "    #create a dictionary and assign each sentence to a dictionary.\n",
        "    #dictionary will hold the sentences of each file\n",
        "    sentences[rid] = []\n",
        "    text = text.strip()\n",
        "    #extract each sentence and assign to corresponding the dictionary\n",
        "    \n",
        "    text = text.replace(\"â€¢\",\" . \")  \n",
        "    text = text.replace(\".\",\". \")  \n",
        "\n",
        "    sentences[rid].extend(sent_detector.tokenize(text))\n",
        "    rid+=1\n",
        "\n",
        "#print(len(sentences))\n",
        "#print(sentences[0])\n",
        "#print(sentences[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content\n",
            "/content/gdrive/My Drive/Colab Notebooks/sec_cleaning/txt\n",
            "/content/gdrive/My Drive/Colab Notebooks/sec_cleaning/txt/output/\n",
            "directory already exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "05S9d78eOcpG",
        "colab": {}
      },
      "source": [
        "import re\n",
        "#import variables\n",
        "\n",
        "causal_verbs = variables.causal_verbs\n",
        "reverse_causal_verbs = variables.reverse_causal_verbs\n",
        "\n",
        "#print(all_verbs)\n",
        "#causal_re = re.compile(\" | \".join(causal_verbs), re.IGNORECASE)\n",
        "#reverse_causal_re = re.compile(\" | \".join(reverse_causal_verbs), re.IGNORECASE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVEe058ROcpK",
        "colab_type": "text"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6-74NOf5OcpQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "5a392cda-bfaf-4218-c48a-0843885312f6"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "count = 0\n",
        "\n",
        "for rid in sentences:\n",
        "    variables.missed_verbs_new = MyFun.get_unique_fileName(os.path.splitext(filenames[rid])[0]+\"_\"+variables.missed_verbs,os.getcwd()+\"/output/\")\n",
        "    Cause_Effect_Pairs_new = MyFun.get_unique_fileName(os.path.splitext(filenames[rid])[0]+\"_\"+variables.Cause_Effect_Pairs,os.getcwd()+\"/output/\")\n",
        "\n",
        "    print(\"\")\n",
        "    print(variables.missed_verbs_new)\n",
        "    print(Cause_Effect_Pairs_new)\n",
        "    print(\"\")\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "    missed_verbs_csv = open(os.getcwd()+\"/output/\"+variables.missed_verbs_new,\"w\") #<===open and write to a csv file  and New file is created.\n",
        "    csvOutput = open(os.getcwd()+\"/output/\"+Cause_Effect_Pairs_new,\"w\")\n",
        "    \n",
        "    csvWriter = csv.writer(csvOutput, quoting = csv.QUOTE_NONNUMERIC)\n",
        "    missed_verbs_writer = csv.writer(missed_verbs_csv, quoting = csv.QUOTE_NONNUMERIC)\n",
        "\n",
        "    csvWriter.writerow([\"file name\",\"direction\",\"verb\",\"cause\",\"effect\",\"sent\"])\n",
        "    missed_verbs_writer.writerow([\"verb\",\"sentence\"])\n",
        "    #csvOutput.close()\n",
        "    missed_verbs_csv.close()\n",
        "\n",
        "\n",
        "    for sent in sentences[rid]:\n",
        "        #parts = get_verb_left_right(sent)\n",
        "        part_list = MyFun.get_verb_left_right(sent)\n",
        "        \n",
        "        if(part_list):\n",
        "          for parts in part_list:\n",
        "            if parts:\n",
        "                verb = parts[0]\n",
        "                if verb.lower() in causal_verbs:\n",
        "                    count += 1\n",
        "                    cause = parts[1]\n",
        "                    effect = parts[2]\n",
        "                    #print(\"Found causal verb and cause-effect pairs: ([{}],[{}],[{}]) from sentence: {}\".format(verb,cause,effect,sent))\n",
        "                    csvWriter.writerow([filenames[rid],\"forward\",verb,cause,effect,sent])\n",
        "                    print(\"f\", end='')\n",
        "                if verb.lower() in reverse_causal_verbs:\n",
        "                    count += 1\n",
        "                    cause = parts[2]\n",
        "                    effect = parts[1]\n",
        "                    csvWriter.writerow([filenames[rid],\"reverse\",verb,cause,effect,sent])\n",
        "                    print(\"b\", end='')\n",
        "                    #print(\"Found reverse causal verb and cause-effect pair: ([{}],[{}],[{}]) from sentence: {}\".format(verb,cause,effect,sent))        \n",
        "                    #print(\"Found {} cause-effect pairs.\".format(count))\n",
        "                \n",
        "                #write to file after every 50 sentence\n",
        "                if(count%30==0):\n",
        "                  csvOutput.close()\n",
        "                  csvOutput = open(os.getcwd()+\"/output/\"+\n",
        "                                   Cause_Effect_Pairs_new,\"a\") # <===open and write to a csv file  and New rows will be appended.\n",
        "                  csvWriter = csv.writer(csvOutput, quoting = csv.QUOTE_NONNUMERIC)\n",
        "\n",
        "\n",
        "    csvOutput.close()\n",
        "    missed_verbs_csv.close()\n",
        "\n",
        "print(\"end of loop\")\n",
        "\n",
        "csvOutput.close()\n",
        "missed_verbs_csv.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "AAL_2_2019_02_25_Missed_verbs.csv\n",
            "AAL_2_2019_02_25_Cause_Effect_Pairs.csv\n",
            "\n",
            ".f..ff...f....f................................................fff.....f.........fff....................ff.........f...f.....f.........f..................f..f...........f.......f.f..ff....ff........f............ff.f........f...f.fff.f.....f..ffff.ffffff......ff...f......f..f..f.................fff.ff....f..........f.......ff.......fff.....fff.ff......ff.ff.....f.............f.f......f.................................fff............ff\n",
            "\n",
            "\n",
            "AAL_3_2018_02_21_Missed_verbs.csv\n",
            "AAL_3_2018_02_21_Cause_Effect_Pairs.csv\n",
            "\n",
            ".f..ff...f...f............................f.......ff.....f.....fff....................ff.........f....f......f.........f...................f..f...........f.....f..f..f."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RzKWzwmgOcpS",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OABuZBnrOcpU",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}