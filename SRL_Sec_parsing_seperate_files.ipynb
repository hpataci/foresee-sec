{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of SRL_Sec_parsing_seperate_files.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FVEjMjoFOco9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0f1bf78a-fdc5-46c0-bbbd-eae5b68253ce"
      },
      "source": [
        "\n",
        "import nltk.data\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "import types\n",
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "!pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
        "#from allennlp.predictors.predictor import Predictor\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "Requirement already satisfied: allennlp==1.0.0 in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: allennlp-models==1.0.0 in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: tensorboardX>=1.2 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (2.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (0.22.2.post1)\n",
            "Requirement already satisfied: overrides==3.0.0 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (3.0.0)\n",
            "Requirement already satisfied: spacy<2.3,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (2.2.4)\n",
            "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (4.41.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (2.10.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (3.2.5)\n",
            "Requirement already satisfied: filelock<3.1,>=3.0 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (3.0.12)\n",
            "Requirement already satisfied: jsonnet>=0.10.0; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (0.16.0)\n",
            "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (2.23.0)\n",
            "Requirement already satisfied: jsonpickle in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (1.4.1)\n",
            "Requirement already satisfied: transformers<2.12,>=2.9 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (2.11.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (0.7)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (3.6.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (1.14.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (1.18.5)\n",
            "Requirement already satisfied: torch<1.6.0,>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (1.5.1+cu101)\n",
            "Requirement already satisfied: word2number>=1.1 in /usr/local/lib/python3.6/dist-packages (from allennlp-models==1.0.0) (1.1)\n",
            "Requirement already satisfied: py-rouge==1.1 in /usr/local/lib/python3.6/dist-packages (from allennlp-models==1.0.0) (1.1)\n",
            "Requirement already satisfied: conllu==3.0 in /usr/local/lib/python3.6/dist-packages (from allennlp-models==1.0.0) (3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp==1.0.0) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp==1.0.0) (3.10.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->allennlp==1.0.0) (0.15.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (1.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (2.0.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (0.7.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (47.3.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (3.0.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp==1.0.0) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp==1.0.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp==1.0.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp==1.0.0) (2020.6.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from jsonpickle->allennlp==1.0.0) (1.6.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<2.12,>=2.9->allennlp==1.0.0) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers<2.12,>=2.9->allennlp==1.0.0) (0.7.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers<2.12,>=2.9->allennlp==1.0.0) (0.1.91)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<2.12,>=2.9->allennlp==1.0.0) (20.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers<2.12,>=2.9->allennlp==1.0.0) (0.0.43)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==1.0.0) (8.4.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==1.0.0) (1.4.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==1.0.0) (1.8.2)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==1.0.0) (0.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==1.0.0) (19.3.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp==1.0.0) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.9 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp==1.0.0) (1.17.9)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp==1.0.0) (0.3.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch<1.6.0,>=1.5.0->allennlp==1.0.0) (0.16.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->jsonpickle->allennlp==1.0.0) (3.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<2.12,>=2.9->allennlp==1.0.0) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<2.12,>=2.9->allennlp==1.0.0) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.9->boto3->allennlp==1.0.0) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.9->boto3->allennlp==1.0.0) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dJRQFHyKOcpB",
        "colab": {}
      },
      "source": [
        "#txt='../sec_cleaning/txt/' #path of txt files from SEC-cleaned  for my Anaconda local\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nAlPoTIEOcpE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "0a0a4039-0f12-4352-b2f7-b6c9ec94ff5c"
      },
      "source": [
        "import glob,os\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "print(os.getcwd())\n",
        "\n",
        "os.chdir(\"/content/gdrive/My Drive/Colab Notebooks/srl/txt\")\n",
        "\n",
        "\n",
        "print(os.getcwd())\n",
        "\n",
        "if( not os.path.isdir(os.getcwd()+\"/output/\")):\n",
        "  os.mkdir(os.getcwd()+\"/output/\")\n",
        "  print(os.getcwd()+\"/output/\")\n",
        "  print(\"directory is created\")\n",
        "else:\n",
        "  print(os.getcwd()+\"/output/\")\n",
        "  print(\"directory already exists\")\n",
        "  \n",
        "import MyFun,variables \n",
        "\n",
        "\n",
        "rid = 0\n",
        "sentences = {}\n",
        "filenames=[]\n",
        "\n",
        "prefixed_files = [filename for filename in glob.glob(\"*.txt\") if filename.startswith(\"AAL_\")] #try for only American Airlines' 10 years. comment out to parse the entire folder.\n",
        "\n",
        "#read file path\n",
        "\n",
        "# for all files replace the below line with the other loop below\n",
        "\n",
        "#for text_path in glob.glob(\"*.txt\"):  # comment to parse the entire txt folder\n",
        "for text_path in prefixed_files:\n",
        "    text = Path(text_path).read_text()\n",
        "    filenames.append(os.path.basename(text_path))\n",
        "    sentences[rid] = []\n",
        "    text = text.strip()\n",
        "    \n",
        "    text = text.replace(\"â€¢\",\" . \")  \n",
        "    text = text.replace(\".\",\". \")  \n",
        "\n",
        "    sentences[rid].extend(sent_detector.tokenize(text))\n",
        "    rid+=1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content\n",
            "/content/gdrive/My Drive/Colab Notebooks/sec_cleaning/txt\n",
            "/content/gdrive/My Drive/Colab Notebooks/sec_cleaning/txt/output/\n",
            "directory already exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "05S9d78eOcpG",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "causal_verbs = variables.causal_verbs\n",
        "reverse_causal_verbs = variables.reverse_causal_verbs\n",
        "\n",
        "# to be used with SRL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVEe058ROcpK",
        "colab_type": "text"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6-74NOf5OcpQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "5a392cda-bfaf-4218-c48a-0843885312f6"
      },
      "source": [
        "\n",
        "count = 0\n",
        "\n",
        "for rid in sentences:\n",
        "    variables.missed_verbs_new = MyFun.get_unique_fileName(os.path.splitext(filenames[rid])[0]+\"_\"+variables.missed_verbs,os.getcwd()+\"/output/\")\n",
        "    Cause_Effect_Pairs_new = MyFun.get_unique_fileName(os.path.splitext(filenames[rid])[0]+\"_\"+variables.Cause_Effect_Pairs,os.getcwd()+\"/output/\")\n",
        "\n",
        "    print(\"\")\n",
        "    print(variables.missed_verbs_new)\n",
        "    print(Cause_Effect_Pairs_new)\n",
        "    print(\"\")\n",
        "\n",
        "    missed_verbs_csv = open(os.getcwd()+\"/output/\"+variables.missed_verbs_new,\"w\") #<===open and write to a csv file  and New file is created.\n",
        "    csvOutput = open(os.getcwd()+\"/output/\"+Cause_Effect_Pairs_new,\"w\")\n",
        "    \n",
        "    csvWriter = csv.writer(csvOutput, quoting = csv.QUOTE_NONNUMERIC)\n",
        "    missed_verbs_writer = csv.writer(missed_verbs_csv, quoting = csv.QUOTE_NONNUMERIC)\n",
        "\n",
        "    csvWriter.writerow([\"file name\",\"direction\",\"verb\",\"cause\",\"effect\",\"sent\"])\n",
        "    missed_verbs_writer.writerow([\"verb\",\"sentence\"])\n",
        "    missed_verbs_csv.close()\n",
        "\n",
        "\n",
        "    for sent in sentences[rid]:\n",
        "        part_list = MyFun.get_verb_left_right(sent)\n",
        "        \n",
        "        if(part_list):\n",
        "          for parts in part_list:\n",
        "            if parts:\n",
        "                verb = parts[0]\n",
        "                if verb.lower() in causal_verbs:\n",
        "                    count += 1\n",
        "                    cause = parts[1]\n",
        "                    effect = parts[2]\n",
        "                    csvWriter.writerow([filenames[rid],\"forward\",verb,cause,effect,sent])\n",
        "                    print(\"f\", end='')\n",
        "                if verb.lower() in reverse_causal_verbs:\n",
        "                    count += 1\n",
        "                    cause = parts[2]\n",
        "                    effect = parts[1]\n",
        "                    csvWriter.writerow([filenames[rid],\"reverse\",verb,cause,effect,sent])\n",
        "                    print(\"b\", end='')\n",
        "                    \n",
        "                if(count%30==0):\n",
        "                  csvOutput.close()\n",
        "                  csvOutput = open(os.getcwd()+\"/output/\"+\n",
        "                                   Cause_Effect_Pairs_new,\"a\") # <===open and write to a csv file  and New rows will be appended.\n",
        "                  csvWriter = csv.writer(csvOutput, quoting = csv.QUOTE_NONNUMERIC)\n",
        "\n",
        "\n",
        "    csvOutput.close()\n",
        "    missed_verbs_csv.close()\n",
        "\n",
        "print(\"end of loop\")\n",
        "\n",
        "csvOutput.close()\n",
        "missed_verbs_csv.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "AAL_2_2019_02_25_Missed_verbs.csv\n",
            "AAL_2_2019_02_25_Cause_Effect_Pairs.csv\n",
            "\n",
            ".f..ff...f....f................................................fff.....f.........fff....................ff.........f...f.....f.........f..................f..f...........f.......f.f..ff....ff........f............ff.f........f...f.fff.f.....f..ffff.ffffff......ff...f......f..f..f.................fff.ff....f..........f.......ff.......fff.....fff.ff......ff.ff.....f.............f.f......f.................................fff............ff\n",
            "\n",
            "\n",
            "AAL_3_2018_02_21_Missed_verbs.csv\n",
            "AAL_3_2018_02_21_Cause_Effect_Pairs.csv\n",
            "\n",
            ".f..ff...f...f............................f.......ff.....f.....fff....................ff.........f....f......f.........f...................f..f...........f.....f..f..f."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RzKWzwmgOcpS",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OABuZBnrOcpU",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}